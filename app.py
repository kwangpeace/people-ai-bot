import os
import random
import logging
from slack_bolt import App
from slack_bolt.adapter.flask import SlackRequestHandler
from flask import Flask, request
import chromadb
from sentence_transformers import SentenceTransformer
from datetime import datetime
import json
from googletrans import Translator
import google.generativeai as genai

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(level=logging.INFO, filename="people_ai_bot.log",
                    format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- ì•± ì´ˆê¸°í™” ---
app = App(
    token=os.environ.get("SLACK_BOT_TOKEN"),
    signing_secret=os.environ.get("SLACK_SIGNING_SECRET")
)
flask_app = Flask(__name__)
handler = SlackRequestHandler(app)

# --- í—¬í¼ í•¨ìˆ˜ ---
def _get_session_greeting(bot_instance, user_id, channel_id):
    session_key = (user_id, channel_id)
    if session_key not in bot_instance.session_tracker:
        bot_instance.session_tracker[session_key] = True
        personality_greeting = random.choice(bot_instance.personalities[bot_instance.current_personality]['greeting'])
        return f"{personality_greeting}\n"
    return ""

# --- ë©”ì¸ ë´‡ í´ë˜ìŠ¤ ---
class PeopleAIBot:
    def __init__(self):
        self.bot_name = "í”¼í”ŒAI"
        self.company_name = "ì¤‘ê³ ë‚˜ë¼"
        self.translator = Translator()
        self.use_gemini = os.environ.get("USE_GEMINI", "true").lower() == "true"
        
        try:
            self.bot_id = app.client.auth_test()['user_id']
            logger.info(f"ë´‡ ID({self.bot_id})ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"ë´‡ IDë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìŠ¬ë™ í† í°ì„ í™•ì¸í•˜ì„¸ìš”. ì˜¤ë¥˜: {e}")
            self.bot_id = None

        if self.use_gemini:
            gemini_api_key = os.environ.get("GEMINI_API_KEY")
            if not gemini_api_key:
                logger.error("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Gemini ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
                self.use_gemini = False
            else:
                genai.configure(api_key=gemini_api_key)
                self.gemini_model = genai.GenerativeModel("gemini-1.5-flash-latest")
                logger.info("Gemini API í™œì„±í™”.")
        else:
            logger.info("Gemini API ë¹„í™œì„±í™”.")

        self.gemini_prompt_template = """
ë‹¹ì‹ ì€ 'ì¤‘ê³ ë‚˜ë¼'ì˜ ì¹œì ˆí•œ AI ë™ë£Œ 'í”¼í”ŒAI'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì œê³µëœ 'ì°¸ê³  ìë£Œ'ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë™ë£Œì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

**í•µì‹¬ ê·œì¹™:**
1.  **ìë£Œ ê¸°ë°˜ ë‹µë³€:** ë‹µë³€ì€ ë°˜ë“œì‹œ 'ì°¸ê³  ìë£Œ' ë‚´ìš©ì—ë§Œ ê·¼ê±°í•´ì•¼ í•©ë‹ˆë‹¤. ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ë¡œ ì¶”ì¸¡í•˜ê±°ë‚˜ ì™¸ë¶€ ì§€ì‹ì„ ì‚¬ìš©í•´ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.
2.  **ìŠ¬ë™ í˜•ì‹ ì¤€ìˆ˜:**
    -   í•µì‹¬ ë‹µë³€ì„ 2~3ì¤„ë¡œ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”.
    -   ëª¨ë“  ë¬¸ì¥("~ë‹¤.", "~ìš”." ë“±) ëì—ëŠ” ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆì„ ì¶”ê°€í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.
    -   í•­ëª©ì„ ë‚˜ì—´í•  ë•ŒëŠ” ê¸€ë¨¸ë¦¬ ê¸°í˜¸(-)ë‚˜ ë²ˆí˜¸ ë§¤ê¸°ê¸°(1., 2.)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    -   í…ìŠ¤íŠ¸ë¥¼ êµµê²Œ(**) ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
3.  **ëª¨ë¥¼ ê²½ìš°:** ì°¸ê³  ìë£Œì—ì„œ ëª…í™•í•œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, "ìŒ, ë¬¸ì˜ì£¼ì‹  ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” ì œê°€ ì§€ê¸ˆ ë°”ë¡œ ëª…í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê¸°ëŠ” ì¡°ê¸ˆ ì–´ë µë„¤ìš”." ì™€ ê°™ì´ ë¶€ë“œëŸ½ê²Œ ë§í•˜ê³  í”¼í”ŒíŒ€ ë¬¸ì˜ë¥¼ ì•ˆë‚´í•˜ì„¸ìš”.

**ëŒ€í™” ì‹œì‘:**
-   ëŒ€í™”ê°€ ì²˜ìŒ ì‹œì‘ë  ë•Œë§Œ "ì•ˆë…•í•˜ì„¸ìš”!" ê°™ì€ ì¸ì‚¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

ì§ˆë¬¸: {query}
ì°¸ê³  ìë£Œ:
---
{context}
---
"""
        self.setup_chroma_db()
        self.setup_personalities()
        self.setup_responses()
        self.setup_ocr_fixes()
        self.setup_key_info()
        self.setup_events()
        
        # ChromaDB ì´ˆê¸°í™” ë° ë°ì´í„° ë¡œë”©
        if self.collection.count() == 0:
            logger.info("ChromaDB ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆì–´ ë¡œì»¬ í…ìŠ¤íŠ¸ íŒŒì¼ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
            text = self.load_local_text_data()
            if text:
                text_chunks = self.split_text_into_chunks(text)
                if text_chunks:
                    embeddings = self.embedding_model.encode(text_chunks)
                    self.collection.add(
                        documents=text_chunks,
                        embeddings=embeddings.tolist(),
                        ids=[f"chunk_{i}" for i in range(len(text_chunks))],
                        metadatas=[{"source": "ë¡œì»¬ ê°€ì´ë“œ í…ìŠ¤íŠ¸ íŒŒì¼", "chunk_id": i} for i in range(len(text_chunks))]
                    )
                    logger.info(f"ë¡œì»¬ í…ìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(text_chunks)}ê°œ ì²­í¬ ì¶”ê°€ë¨.")
                else:
                    logger.warning("ë¡œì»¬ í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ìœ íš¨í•œ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            logger.info("ChromaDB ì»¬ë ‰ì…˜ì— ì´ë¯¸ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì—¬ ë¡œì»¬ íŒŒì¼ ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

        self.question_log = []
        self.session_tracker = {}

    def load_local_text_data(self, file_path="guide_data.txt"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
            logger.info(f"ë¡œì»¬ íŒŒì¼ '{file_path}'ì—ì„œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            for wrong, correct in self.ocr_fixes.items():
                text = text.replace(wrong, correct)
            return text
        except FileNotFoundError:
            logger.error(f"ë°ì´í„° íŒŒì¼ '{file_path}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ ê²½ë¡œì— íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            return ""
        except Exception as e:
            logger.error(f"ë¡œì»¬ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return ""

    def setup_chroma_db(self):
        db_path = os.environ.get("CHROMA_DB_PATH", "./chroma_db")
        self.chroma_client = chromadb.PersistentClient(path=db_path)
        self.collection = self.chroma_client.get_or_create_collection(
            name="junggonara_guide",
            metadata={"description": "ì¤‘ê³ ë‚˜ë¼ íšŒì‚¬ ê°€ì´ë“œ ë°ì´í„°"}
        )
        self.embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        logger.info(f"ChromaDB({db_path}) ë° SentenceTransformer ì„¤ì • ì™„ë£Œ.")

    def setup_personalities(self):
        self.current_personality = "friendly"
        self.personalities = {
            "professional": {"name": "í”¼í”ŒAI í”„ë¡œ", "greeting": ["ì•ˆë…•í•˜ì„¸ìš”! ì¤‘ê³ ë‚˜ë¼ í”¼í”ŒAI í”„ë¡œì…ë‹ˆë‹¤.", "ì •í™•í•œ ë‹µë³€ìœ¼ë¡œ ë„ì™€ë“œë¦´ê²Œìš”."]},
            "friendly": {"name": "í”¼í”ŒAI ì¹œêµ¬", "greeting": ["ì•ˆë…•! ì¤‘ê³ ë‚˜ë¼ ë™ë£Œë“¤ì˜ ì¹œêµ¬, í”¼í”ŒAIì•¼.", "í¸í•˜ê²Œ ë¬¼ì–´ë³´ì!"]},
            "cheerful": {"name": "í”¼í”ŒAI í•´í”¼", "greeting": ["ì¢‹ì€ í•˜ë£¨! í”¼í”ŒAI í•´í”¼ ëª¨ë“œì•¼.", "ì–´ë–¤ ë„ì›€ì„ ì¤„ê¹Œ?"]}
        }
        logger.info("ì„±ê²© ì„¤ì • ì™„ë£Œ.")

    def setup_responses(self):
        self.responses = {
            "searching": [
                "ìƒê°í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... ğŸ¤”",
                "ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”. í”¼í”ŒAIê°€ ì—´ì‹¬íˆ ë‹µì„ ì°¾ê³  ìˆì–´ìš”! ğŸƒâ€â™‚ï¸",
                "ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆì–´ìš”. ê³§ ë‹µë³€í•´ ë“œë¦´ê²Œìš”! ğŸ“Š",
                "ê°€ì´ë“œë¶ì„ ìƒ…ìƒ…ì´ ë’¤ì§€ëŠ” ì¤‘... ğŸ“š"
            ],
            "not_found": ["ìŒ, ë¬¸ì˜ì£¼ì‹  ë¶€ë¶„ì€ ì œê°€ ì§€ê¸ˆ ëª…í™•íˆ ë‹µë³€ë“œë¦¬ê¸° ì–´ë µë„¤ìš”. âš ï¸", "ì œê°€ ì•„ëŠ” ì„ ì—ì„œëŠ” í•´ë‹¹ ì •ë³´ê°€ í™•ì¸ë˜ì§€ ì•Šì•„ìš”. âŒ"]
        }
        logger.info("ì‘ë‹µ ë©”ì‹œì§€ ì„¤ì • ì™„ë£Œ.")

    def setup_ocr_fixes(self):
        self.ocr_fixes = {
            "ì—°ì¹˜": "ì—°ì°¨", "ë³µë¦¬í›„ì…": "ë³µë¦¬í›„ìƒ", "íšŒìœ¼ì‹¤": "íšŒì˜ì‹¤",
            "íƒë°°ì‹¤": "íƒë°°ì‹¤", "ê²°ì œ": "ê²°ì¬", "ê¸‰ì—¬ëª…ì„¸ì„œ": "ê¸‰ì—¬ëª…ì„¸ì„œ"
        }
        logger.info("OCR ìˆ˜ì • ë§µ ì„¤ì • ì™„ë£Œ.")
    
    def setup_key_info(self):
        """AIê°€ ë†“ì¹˜ê¸° ì‰¬ìš´ í•µì‹¬ ì •ë³´ë¥¼ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤."""
        self.key_info = [
            {
                "keywords": ["ì£¼ì†Œ", "ìœ„ì¹˜", "ì–´ë””"],
                "answer": "âœ… ìš°ë¦¬ íšŒì‚¬ ì£¼ì†ŒëŠ” 'ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 415, L7 HOTELS ê°•ë‚¨íƒ€ì›Œ 4ì¸µ'ì…ë‹ˆë‹¤."
            },
            {
                "keywords": ["ì™€ì´íŒŒì´", "wifi", "wi-fi", "ì¸í„°ë„·"],
                "answer": "âœ… ì§ì›ìš© ì™€ì´íŒŒì´ëŠ” 'joonggonara-5G'ì´ë©°, ë¹„ë°€ë²ˆí˜¸ëŠ” 'jn2023!@'ì…ë‹ˆë‹¤.\nâœ… ë°©ë¬¸ê°ìš©ì€ 'joonggonara-guest-5G'ì´ë©°, ë¹„ë°€ë²ˆí˜¸ëŠ” 'guest2023!@'ì…ë‹ˆë‹¤."
            },
            {
                "keywords": ["íƒë°°ë§ˆê°", "íƒë°° ë§ˆê°", "íƒë°°ì‹œê°„", "íƒë°° ì‹œê°„"],
                "answer": "âœ… ì‚¬ë‚´ íƒë°° ë§ˆê° ì‹œê°„ì€ í‰ì¼ ì˜¤í›„ 1ì‹œì…ë‹ˆë‹¤. ì£¼ë§ì—ëŠ” ìˆ˜ê±°í•˜ì§€ ì•Šìœ¼ë‹ˆ ì°¸ê³ í•´ì£¼ì„¸ìš”."
            },
            {
                "keywords": ["ê·¼íƒœ ë‹´ë‹¹ì", "ê·¼íƒœë‹´ë‹¹ì", "ê·¼íƒœ ë¬¸ì˜"],
                "answer": "âœ… Flex ê·¼íƒœ, íœ´ê°€ ê´€ë ¨ ë¬¸ì˜ëŠ” í”¼í”ŒíŒ€ ì´ì„±í—Œë‹˜ê»˜ í•˜ì‹œë©´ ë©ë‹ˆë‹¤."
            },
            {
                "keywords": ["ë§›ì§‘", "ë°¥ì§‘", "ì ì‹¬", "ì €ë…"],
                "answer": "âœ… ì¤‘ê³ ë‚˜ë¼ ë³¸ì‚¬ ê·¼ì²˜ ë§›ì§‘ ì •ë³´ëŠ” ê°€ì´ë“œ ë¬¸ì„œì— ì •ë¦¬ë˜ì–´ ìˆì–´ìš”. 'ì£¼ë³€ ë§›ì§‘ ë¦¬ìŠ¤íŠ¸'ë¼ê³  ë¬¼ì–´ë³´ì‹œë©´ ë” ìì„¸íˆ ì•Œë ¤ë“œë¦´ê²Œìš”!"
            },
            {
                "keywords": ["ì›¹ì‚¬ì´íŠ¸", "í™ˆí˜ì´ì§€", "ë¸”ë¡œê·¸"],
                "answer": "âœ… ì¤‘ê³ ë‚˜ë¼ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ì£¼ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n- ì¤‘ê³ ë‚˜ë¼ ì„œë¹„ìŠ¤: https://www.joongna.com/\n- ì¤‘ê³ ë‚˜ë¼ ê¸°ìˆ  ë¸”ë¡œê·¸: https://teamblog.joonggonara.co.kr/"
            }
        ]
        logger.info("ì£¼ìš” ì •ë³´(Key Info) ì„¤ì • ì™„ë£Œ.")

    def setup_events(self):
        self.events = [
            {"name": "ë¶„ê¸°ë³„ íƒ€ìš´í™€ ë¯¸íŒ…", "date": "2025-09-15", "details": "ğŸ‘¥ ì „ ì§ì› ì°¸ì—¬, ì˜¤í›„ 2ì‹œ ëŒ€íšŒì˜ì‹¤ ğŸ¢"},
            {"name": "ì—°ë§ íŒŒí‹°", "date": "2025-12-20", "details": "ğŸ‰ ì‚¬ë‚´ ì—°ë§ í–‰ì‚¬, ë“œë ˆìŠ¤ ì½”ë“œ: ìºì£¼ì–¼"}
        ]
        logger.info("ì´ë²¤íŠ¸ ì„¤ì • ì™„ë£Œ.")

    def split_text_into_chunks(self, text, max_length=1000, overlap=100):
        """ì˜ë¯¸ ë‹¨ìœ„(ë¬¸ë‹¨)ë¥¼ ìœ ì§€í•˜ë©° í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤."""
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        
        chunks = []
        for paragraph in paragraphs:
            if len(paragraph) <= max_length:
                chunks.append(paragraph)
            else:
                sentences = [s.strip() for s in paragraph.split('.') if s.strip()]
                current_chunk = ""
                for sentence in sentences:
                    if len(current_chunk) + len(sentence) + 1 <= max_length:
                        current_chunk += sentence + ". "
                    else:
                        chunks.append(current_chunk.strip())
                        current_chunk = current_chunk[-overlap:] + sentence + ". "
                if current_chunk:
                    chunks.append(current_chunk.strip())
        
        return [chunk for chunk in chunks if len(chunk) > 50]

    def is_question_pattern(self, text):
        question_keywords = ["ì–´ë–»ê²Œ", "ë°©ë²•", "ì•Œë ¤ì¤˜", "ë­ì•¼", "ì–¸ì œ", "ì–´ë””ì„œ", "ëˆ„êµ¬", "ì—°ì°¨", "íšŒì˜ì‹¤", "íƒë°°", "ë³µë¦¬í›„ìƒ", "ê¶ê¸ˆ"]
        return any(keyword in text.lower() for keyword in question_keywords)

    def detect_and_translate_language(self, text):
        try:
            detected = self.translator.detect(text)
            if detected.lang != 'ko' and detected.lang != 'en':
                translated_text = self.translator.translate(text, dest='ko').text
                logger.info(f"'{detected.lang}' -> 'ko'ë¡œ ë²ˆì—­ë¨. ì›ë³¸: '{text[:20]}...', ë²ˆì—­: '{translated_text[:20]}...'")
                return translated_text
            return text
        except Exception as e:
            logger.error(f"ì–¸ì–´ ê°ì§€ ë˜ëŠ” ë²ˆì—­ ì‹¤íŒ¨: {e}", exc_info=True)
            return text

    def search_knowledge(self, query, n_results=5):
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ í‚¤ì›Œë“œ ê²€ìƒ‰ í›„, AI ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        processed_query = self.detect_and_translate_language(query)
        for wrong, correct in self.ocr_fixes.items():
            processed_query = processed_query.replace(wrong, correct)
        
        # 1. Key Info (í‚¤ì›Œë“œ) ê²€ìƒ‰
        for info in self.key_info:
            for keyword in info["keywords"]:
                if keyword in processed_query:
                    logger.info(f"ì£¼ìš” ì •ë³´ì—ì„œ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ({keyword}) ë°œê²¬.")
                    return [info["answer"]], "key_info"

        # 2. RAG (ChromaDB + Gemini)
        try:
            context_docs = self.collection.query(
                query_embeddings=self.embedding_model.encode([processed_query]).tolist(),
                n_results=n_results
            )
            context = "\n\n".join(context_docs['documents'][0]) if context_docs and context_docs['documents'] else ""
            logger.info(f"ChromaDB ê²€ìƒ‰ ì™„ë£Œ. ì¿¼ë¦¬: {processed_query[:50]}... {n_results}ê°œ ê²°ê³¼ ì‚¬ìš©.")
        except Exception as e:
            logger.error(f"ChromaDB ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=True)
            context = ""

        if self.use_gemini and context:
            try:
                prompt = self.gemini_prompt_template.format(query=processed_query, context=context)
                gemini_response = self.gemini_model.generate_content(prompt)
                
                if gemini_response and hasattr(gemini_response, 'text') and gemini_response.text:
                    logger.info(f"Gemini API ì‘ë‹µ ì„±ê³µ. ì¿¼ë¦¬: {processed_query[:50]}...")
                    return [gemini_response.text], "gemini"
                else:
                    logger.warning(f"Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‘ë‹µ: {gemini_response}")
            except Exception as e:
                logger.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
        
        return [], "not_found"

    def generate_response(self, query, relevant_data, response_type, user_id, channel_id):
        greeting = _get_session_greeting(self, user_id, channel_id)
        
        if response_type == "key_info":
            response_text = relevant_data[0]
            response = f"{greeting}{response_text}"
        elif response_type == "gemini":
            response_text = relevant_data[0]
            response = f"{greeting}{response_text}"
        else: # not_found
            response_text = random.choice(self.responses['not_found'])
            response = f"{greeting}{response_text}\ní”¼í”ŒíŒ€ ë‹´ë‹¹ìì—ê²Œ ë¬¸ì˜í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”? ğŸ“"

        return response, response_type

    def log_question(self, query, response_text, response_type):
        self.question_log.append({
            "query": query,
            "response": response_text,
            "response_type": response_type,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "personality": self.current_personality
        })
        logger.info(f"ì§ˆë¬¸ ë¡œê·¸ ê¸°ë¡: ì¿¼ë¦¬='{query[:50]}...', ì‘ë‹µ íƒ€ì…='{response_type}'")

# --- ë´‡ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---
bot = PeopleAIBot()

# --- Slack ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
@app.message(".*")
def handle_message(message, say):
    try:
        user_query = message['text']
        channel_id = message['channel']
        user_id = message['user']
        
        if message.get('user') == bot.bot_id:
            return

        auto_respond_channels_env = os.environ.get("AUTO_RESPOND_CHANNELS", "")
        auto_respond_channels = [c.strip() for c in auto_respond_channels_env.split(',') if c.strip()]
        
        if (bot.bot_id and f"<@{bot.bot_id}>" in user_query or
            message.get('channel_type') == 'im' or
            (channel_id in auto_respond_channels and bot.is_question_pattern(user_query))):
            
            clean_query = user_query.replace(f"<@{bot.bot_id}>", "").strip() if bot.bot_id else user_query.strip()
            
            if not clean_query or len(clean_query) < 2:
                logger.info(f"ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹ˆ ì¿¼ë¦¬ ë¬´ì‹œë¨. ì¿¼ë¦¬: '{clean_query}'")
                return
            
            say(random.choice(bot.responses['searching']))
            
            relevant_data, response_type = bot.search_knowledge(clean_query)
            response, final_response_type = bot.generate_response(clean_query, relevant_data, response_type, user_id, channel_id)
            say(response)
            bot.log_question(clean_query, response, final_response_type)
            
    except Exception as e:
        logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        say(f"ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. âš ï¸\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

@app.message("í”¼í”ŒAI ë„ì›€ë§")
def handle_help(message, say):
    user_id = message['user']
    channel_id = message['channel']
    greeting_prefix = _get_session_greeting(bot, user_id, channel_id)

    help_text = """ë„ì›€ë§ì„ ì•Œë ¤ë“œë¦´ê²Œìš”. âœ¨
í”¼í”ŒAIëŠ” ì¤‘ê³ ë‚˜ë¼ ì§ì›ë“¤ì˜ íšŒì‚¬ìƒí™œì„ ë•ëŠ” AIì…ë‹ˆë‹¤.
íšŒì‚¬ ì •ì±…, ë³µì§€, ì ˆì°¨ ë“±ì„ ì§ˆë¬¸í•˜ì‹œë©´ ë¹ ë¥´ê²Œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.

ğŸ“‹ ì‚¬ìš© ì˜ˆì‹œ:
- `@í”¼í”ŒAI ì—°ì°¨ ì‹ ì²­ ë°©ë²•`
- `#people-team-help` ì±„ë„ì—ì„œ: `íƒë°° ë°œì†¡ ì ˆì°¨ëŠ”?`
- DMìœ¼ë¡œ: `How to book a meeting room?`

ğŸ“ ëª…ë ¹ì–´:
- `í”¼í”ŒAI ëª¨ë“œë³€ê²½`: ì„±ê²© ë³€ê²½ (í”„ë¡œ/ì¹œêµ¬/í•´í”¼)
- `í”¼í”ŒAI ì˜¤ëŠ˜ì˜íŒ`: íšŒì‚¬ìƒí™œ íŒ
- `í”¼í”ŒAI ë§›ì§‘ì¶”ì²œ`: íšŒì‚¬ ê·¼ì²˜ ë§›ì§‘
- `í”¼í”ŒAI ì´ë²¤íŠ¸`: ì‚¬ë‚´ ì´ë²¤íŠ¸ í™•ì¸

ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.
"""
    response = greeting_prefix + help_text
    say(response)

@app.message("í”¼í”ŒAI ëª¨ë“œë³€ê²½")
def change_mode(message, say):
    user_id = message['user']
    channel_id = message['channel']
    greeting_prefix = _get_session_greeting(bot, user_id, channel_id)

    personalities = list(bot.personalities.keys())
    current_index = personalities.index(bot.current_personality)
    next_index = (current_index + 1) % len(personalities)
    bot.current_personality = personalities[next_index]
    
    new_mode_name = bot.personalities[bot.current_personality]['name']
    
    response_text = f"ëª¨ë“œ ë³€ê²½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. âœ…\ní˜„ì¬ ëª¨ë“œëŠ” {new_mode_name}ì…ë‹ˆë‹¤.\nì–´ë–¤ ë„ì›€ì„ ë“œë¦´ê¹Œìš”?\n"
    response = greeting_prefix + response_text
    say(response)

@app.message("í”¼í”ŒAI ì˜¤ëŠ˜ì˜íŒ")
def daily_tip(message, say):
    user_id = message['user']
    channel_id = message['channel']
    greeting_prefix = _get_session_greeting(bot, user_id, channel_id)

    tips = [
        "ğŸ’¡ ì´ë©”ì¼ ì œëª©ì€ ëª…í™•íˆ ì‘ì„±í•˜ì„¸ìš”.\nì˜ˆì‹œ: 'íšŒì˜' ëŒ€ì‹  '3/15 ë§ˆì¼€íŒ… íšŒì˜'ë¡œ!",
        "â° íšŒì˜ 5ë¶„ ì „ ì…ì¥í•˜ë©´ ì¸ìƒ ì¢‹ì•„ìš”.",
        "ğŸ’° ì‚¬ë‚´ ì‹ë‹¹ ë¬´ë£Œ ë·”í˜ë¥¼ ê¼­ ì´ìš©í•˜ì„¸ìš”. ì ì‹¬ ì‹ë¹„ ì ˆì•½ì— ìµœê³ ! ğŸ˜‹"
    ]
    
    tip = random.choice(tips)
    response_text = f"ì˜¤ëŠ˜ì˜ íŒì„ ë“œë¦´ê²Œìš”. ğŸ“‹\n{tip}\në” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.\n"
    response = greeting_prefix + response_text
    say(response)

@app.message("í”¼í”ŒAI ë§›ì§‘ì¶”ì²œ")
def recommend_restaurant(message, say):
    user_id = message['user']
    channel_id = message['channel']
    greeting_prefix = _get_session_greeting(bot, user_id, channel_id)

    restaurants = [
        "ğŸœ ë¼ë©˜ì§‘: ëˆì½”ì¸  ë¼ë©˜ ë§›ì§‘ (ë„ë³´ 5ë¶„)",
        "ğŸ• í”¼ììŠ¤ì¿¨: ì ì‹¬ íŠ¹ê°€ í”¼ì (ë„ë³´ 3ë¶„)",
        "ğŸ± í•œì†¥ë„ì‹œë½: ê°„í¸í•œ ë„ì‹œë½ (ë„ë³´ 2ë¶„)",
        "â˜• ìŠ¤íƒ€ë²…ìŠ¤: íšŒì˜í•˜ê¸° ì¢‹ì€ ì¹´í˜ (ë„ë³´ 1ë¶„)"
    ]
    
    recommended = '\n'.join(random.sample(restaurants, 2))
    response_text = f"ì¤‘ê³ ë‚˜ë¼ ê·¼ì²˜ ë§›ì§‘ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. ğŸ¢\n{recommended}\në” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.\n"
    response = greeting_prefix + response_text
    say(response)

@app.message("í”¼í”ŒAI ì´ë²¤íŠ¸")
def events(message, say):
    user_id = message['user']
    channel_id = message['channel']
    greeting_prefix = _get_session_greeting(bot, user_id, channel_id)

    today = datetime.now()
    upcoming = [e for e in bot.events if datetime.strptime(e['date'], "%Y-%m-%d") >= today]

    if upcoming:
        event_list = [f"- {e['name']} ({e['date']}): {e['details']}" for e in upcoming]
        event_list_str = '\n'.join(event_list)
        response_text = f"ë‹¤ê°€ì˜¤ëŠ” ì´ë²¤íŠ¸ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ğŸ“…\nì´ë²¤íŠ¸ ëª©ë¡:\n{event_list_str}\në” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.\n"
    else:
        response_text = """í˜„ì¬ ì˜ˆì •ëœ ì´ë²¤íŠ¸ëŠ” ì—†ìŠµë‹ˆë‹¤. ğŸ˜”
ìƒˆë¡œìš´ ì´ë²¤íŠ¸ê°€ ìƒê¸°ë©´ ë¹ ë¥´ê²Œ ì•Œë ¤ë“œë¦´ê²Œìš”!
ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.
"""
    response = greeting_prefix + response_text
    say(response)

# --- Flask ë¼ìš°íŒ… ---
@flask_app.route("/slack/events", methods=["POST"])
def slack_events():
    return handler.handle(request)

@flask_app.route("/", methods=["GET"])
def health_check():
    return "í”¼í”ŒAI ì •ìƒ ì‘ë™ì¤‘! ğŸŸ¢"

# --- ì•± ì‹¤í–‰ ---
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 3000))
    logger.info(f"Flask ì•±ì„ í¬íŠ¸ {port}ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    flask_app.run(host="0.0.0.0", port=port)
